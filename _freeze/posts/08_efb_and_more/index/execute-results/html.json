{
  "hash": "75e7e2488d9dba4323c3ecc53eb8086f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Exclusive Feature Bundling and More\"\ndescription: \"Can this LightGBM master piece help us uncover more things?\"\ndate: \"2025-01-05\"\ntags: [metric, classification, python, modelling]\nimage: crossroad-unsplash.jpg\ndraft: true\n---\n\n::: {#adecf377 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport random\n\nclass ExclusiveFeatureBundling:\n    \"\"\"\n    Implementation of Exclusive Feature Bundling (EFB) similar to LightGBM.\n\n    This is a simplified implementation for demonstration purposes and\n    doesn't include all optimizations or features of the original LightGBM\n    implementation.\n\n    Attributes:\n        max_conflict_rate (float): Maximum conflict rate allowed for bundling.\n        max_features_per_bundle (int): Maximum number of features allowed in a bundle.\n\n    \"\"\"\n\n    def __init__(self, max_conflict_rate=0.05, max_features_per_bundle=10):\n        \"\"\"\n        Initializes the ExclusiveFeatureBundling class.\n\n        Args:\n            max_conflict_rate (float): Maximum allowed conflict rate between features in a bundle.\n            max_features_per_bundle (int): Maximum number of features allowed in a single bundle.\n        \"\"\"\n        self.max_conflict_rate = max_conflict_rate\n        self.max_features_per_bundle = max_features_per_bundle\n\n\n    def _calculate_conflict(self, feature1, feature2):\n        \"\"\"\n        Calculates the conflict between two features.\n\n        Conflict is defined as the proportion of data points where both features\n        have non-zero values.  Features are considered conflicting if they frequently\n        have nonzero values simultaneously.\n\n        Args:\n            feature1 (np.array): First feature vector.\n            feature2 (np.array): Second feature vector.\n\n        Returns:\n            float: Conflict rate between the two features.\n        \"\"\"\n        non_zero_indices1 = np.nonzero(feature1)[0]\n        non_zero_indices2 = np.nonzero(feature2)[0]\n        intersection = np.intersect1d(non_zero_indices1, non_zero_indices2)\n        conflict = len(intersection) / len(feature1)  # Proportion of conflicts.\n\n        return conflict\n\n    def find_bundles(self, data):\n        \"\"\"\n        Finds exclusive feature bundles in the given data.\n\n        Args:\n            data (np.ndarray): Input data matrix (num_samples x num_features).\n\n        Returns:\n            list: A list of bundles, where each bundle is a list of feature indices.\n        \"\"\"\n        num_features = data.shape[1]\n        features_available = list(range(num_features))\n        bundles = []\n\n        # Sort features by sparsity (number of non-zero values).\n        sparsity = [np.count_nonzero(data[:, i]) / data.shape[0] for i in range(num_features)]\n        sorted_features = sorted(features_available, key=lambda x: sparsity[x])\n\n        while sorted_features:\n            # Start a new bundle\n            bundle = [sorted_features.pop(0)]\n            bundled_features = set(bundle) #Use a set for faster checking if a feature is bundled\n            # Try to add more features to the bundle\n            for feature_idx in list(sorted_features):\n                add_to_bundle = True\n                for bundled_feature_idx in bundle:\n                    conflict = self._calculate_conflict(data[:, bundled_feature_idx], data[:, feature_idx])\n                    if conflict > self.max_conflict_rate:\n                        add_to_bundle = False\n                        break\n                if add_to_bundle and len(bundle) < self.max_features_per_bundle:\n                    bundle.append(feature_idx)\n                    sorted_features.remove(feature_idx)  # Remove from available features\n            bundles.append(bundle)\n\n        return bundles\n\n    def apply_bundles(self, data, bundles):\n        \"\"\"\n        Applies the feature bundles to the data.\n\n        Args:\n            data (np.ndarray): Input data matrix (num_samples x num_features).\n            bundles (list): A list of bundles (lists of feature indices).\n\n        Returns:\n            np.ndarray: A new data matrix with bundled features.\n        \"\"\"\n\n        bundled_data = []\n        for bundle in bundles:\n            if len(bundle) == 1:\n                bundled_data.append(data[:, bundle[0]])  # Keep single features\n            else:\n                # Combine features within the bundle using a simple method (sum)\n                # In practice, more sophisticated combination methods can be used\n                bundled_feature = np.nansum(data[:, bundle], axis=1)\n                bundled_data.append(bundled_feature)\n\n        return np.column_stack(bundled_data) #Concatenate horizontally\n\n```\n:::\n\n\n::: {#e7289f31 .cell execution_count=2}\n``` {.python .cell-code}\n# Create a sample dataset (replace with your actual data)\nnp.random.seed(42)\nnum_samples = 10000\nnum_features = 5\ndata1 = np.random.randint(0, 50, size=(num_samples, num_features)).astype(float)\ndata1[data1 < 5] = np.nan  # Simulate sparsity in lower bounds\ndata1[data1 > 45] = 0  # Simulate sparsity in  upper bounds\n\n\ndata2 = np.random.poisson(lam=3, size=(num_samples, num_features)).astype(float)\ndata2[data2 < 0.5] = 0  # Simulate sparsity in lower bounds\ndata2[data2 > 10] = np.nan  # Simulate sparsity in  upper bounds\n\ndata3 = np.random.noncentral_f(dfnum=3, dfden=20, nonc=3, size=(num_samples, num_features))\ndata3[data3 < 0.5] = np.nan  # Simulate sparsity in lower bounds\ndata3[data3 > 3.8] = np.nan  # Simulate sparsity in  upper bounds\n\ndata = np.column_stack([data1,data2,data3])\n\n\nprobability_of_conflict = num_features*100/num_samples\n\nprint(data[:5,:])\n\nsparsity = [np.count_nonzero(data[:, i]) / data.shape[0] for i in range(num_features*3)]\n\nprint('\\nConflict probability based on size',probability_of_conflict)\nprint('Original Sparsity',sparsity)\n\n# Initialize the EFB class\nefb = ExclusiveFeatureBundling(max_conflict_rate=0.9, max_features_per_bundle=7)\n\n# Find feature bundles\nbundles = efb.find_bundles(data)\nprint(\"Found bundles:\", bundles)\n\n# Apply the bundles to the data\nbundled_data = efb.apply_bundles(data, bundles)\nprint(\"Original number of features:\", num_features)\nprint(\"Number of bundled features:\", bundled_data.shape[1])\nprint(\"Bundled data shape:\", bundled_data.shape)\nprint(bundled_data[:5,:])\n\nsparsity = [np.count_nonzero(bundled_data[:, i]) / bundled_data.shape[0] for i in range(bundled_data.shape[1])]\nprint('Bundle Sparsity',sparsity)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[38.         28.         14.         42.          7.          8.\n   1.          2.          2.          1.          1.06053997         nan\n          nan  0.53527748  0.84192902]\n [20.         38.         18.         22.         10.          3.\n   1.          4.          4.          4.          1.29541796  0.52676978\n   2.20838618         nan  0.98007732]\n [10.         23.         35.         39.         23.          2.\n   1.          2.          2.          5.          3.655994    2.84812236\n   2.05293381  0.55366503  1.28826306]\n [        nan 21.                 nan 23.         43.          3.\n   2.          6.          4.          4.          2.25425123  1.68307329\n   0.60545256         nan  1.94761522]\n [29.         37.                 nan 20.         32.          2.\n   1.          2.          5.          3.          0.6528372   1.44338609\n          nan         nan         nan]]\n\nConflict probability based on size 0.05\nOriginal Sparsity [0.9166, 0.9168, 0.9217, 0.9179, 0.9215, 0.9513, 0.952, 0.9589, 0.949, 0.9501, 1.0, 1.0, 1.0, 1.0, 1.0]\nFound bundles: [[0, 1, 3, 4, 2, 8], [9], [5], [6], [7], [10], [11], [12], [13], [14]]\nOriginal number of features: 5\nNumber of bundled features: 10\nBundled data shape: (10000, 10)\n[[131.           1.           8.           1.           2.\n    1.06053997          nan          nan   0.53527748   0.84192902]\n [112.           4.           3.           1.           4.\n    1.29541796   0.52676978   2.20838618          nan   0.98007732]\n [132.           5.           2.           1.           2.\n    3.655994     2.84812236   2.05293381   0.55366503   1.28826306]\n [ 91.           4.           3.           2.           6.\n    2.25425123   1.68307329   0.60545256          nan   1.94761522]\n [123.           3.           2.           1.           2.\n    0.6528372    1.44338609          nan          nan          nan]]\nBundle Sparsity [1.0, 0.9501, 0.9513, 0.952, 0.9589, 1.0, 1.0, 1.0, 1.0, 1.0]\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}